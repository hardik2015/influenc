{
  "52": {
    "inputs": {
      "filename_prefix": "%date:yyyy-MM-dd - hh.mm.ss%",
      "sampler_selection_method": "Farthest",
      "sampler_selection_node_id": 0,
      "file_format": "png",
      "lossless_webp": true,
      "quality": 100,
      "save_workflow_json": false,
      "add_counter_to_filename": true,
      "civitai_sampler": false,
      "save_workflow_image": true,
      "images": [
        "495",
        0
      ]
    },
    "class_type": "SaveImageWithMetaData",
    "_meta": {
      "title": "SaveImageWithMetaData"
    }
  },
  "54": {
    "inputs": {
      "text": [
        "423",
        2
      ],
      "clip": [
        "423",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "55": {
    "inputs": {
      "samples": [
        "272",
        0
      ],
      "vae": [
        "503",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "163": {
    "inputs": {
      "wildcard_text": "A happy woman, (blushing:1.4), {open mouth|}, smiling holding a large beer, smiling, in festive clothes. Deep clevage. Downblouse. {drinking}",
      "populated_text": "A happy woman, (blushing:1.4), , smiling holding a large beer, smiling, in festive clothes. Deep clevage. Downblouse. drinking",
      "mode": "reproduce",
      "seed": 687462579387495,
      "Select to add Wildcard": "Select the Wildcard to add to the text"
    },
    "class_type": "ImpactWildcardProcessor",
    "_meta": {
      "title": "Positive Prompt w. Wildcards"
    }
  },
  "272": {
    "inputs": {
      "seed": 223034662937912,
      "steps": 16,
      "cfg": 1.5,
      "sampler_name": "lcm",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "423",
        0
      ],
      "positive": [
        "54",
        0
      ],
      "negative": [
        "276",
        0
      ],
      "latent_image": [
        "422",
        4
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "276": {
    "inputs": {
      "text": "watermark, text, simple background, flash, dark, night",
      "clip": [
        "423",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "291": {
    "inputs": {
      "seed": 984332556946817,
      "steps": 8,
      "cfg": 1.8,
      "sampler_name": "lcm",
      "scheduler": "simple",
      "denoise": 0.3,
      "model": [
        "423",
        0
      ],
      "positive": [
        "54",
        0
      ],
      "negative": [
        "276",
        0
      ],
      "latent_image": [
        "513",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "292": {
    "inputs": {
      "samples": [
        "291",
        0
      ],
      "vae": [
        "503",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "422": {
    "inputs": {
      "preset": "SDXL: [Portrait] 768x1344 9:16",
      "preset_user": "Favorites: [Portrait] 540x960 9:16",
      "custom_width": 512,
      "custom_height": 512,
      "multiply_scale": 2,
      "swap_width_and_height": false,
      "image_min_length": 0,
      "image_max_length": 0,
      "snap_to_nearest": false,
      "snap_resolution": 0,
      "batch_size": 1
    },
    "class_type": "üìê Resolution Image Size Selector",
    "_meta": {
      "title": "üìê Resolution Image Size Selector"
    }
  },
  "423": {
    "inputs": {
      "MODEL": [
        "503",
        0
      ],
      "CLIP": [
        "503",
        1
      ],
      "STRING": [
        "163",
        0
      ]
    },
    "class_type": "üè∑Ô∏è LoRA Loader Prompt Tags",
    "_meta": {
      "title": "üè∑Ô∏è LoRA Loader Prompt Tags"
    }
  },
  "486": {
    "inputs": {
      "model_name": "bbox/hand_yolov8s.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "Hand Model Loader"
    }
  },
  "487": {
    "inputs": {
      "detailer_pipe": [
        "496",
        4
      ]
    },
    "class_type": "FromDetailerPipe",
    "_meta": {
      "title": "FromDetailerPipe"
    }
  },
  "488": {
    "inputs": {
      "model_name": "bbox/face_yolov8s.pt"
    },
    "class_type": "UltralyticsDetectorProvider",
    "_meta": {
      "title": "UltralyticsDetectorProvider"
    }
  },
  "489": {
    "inputs": {
      "text": "ugly",
      "clip": [
        "423",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "490": {
    "inputs": {
      "text": "hand, (detailed realistic skin:0.2)",
      "clip": [
        "487",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "491": {
    "inputs": {
      "String": "perfect eyes, (detailed realistic skin:0.3)"
    },
    "class_type": "String",
    "_meta": {
      "title": "Face Detailer Appended Prompt"
    }
  },
  "492": {
    "inputs": {
      "string_a": [
        "423",
        2
      ],
      "string_b": [
        "491",
        0
      ]
    },
    "class_type": "ConcatStringSingle",
    "_meta": {
      "title": "Concat String (Single) üìÖüÖïüÖù"
    }
  },
  "493": {
    "inputs": {
      "text": [
        "492",
        0
      ],
      "clip": [
        "423",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "495": {
    "inputs": {
      "guide_size": 1536,
      "guide_size_for": true,
      "max_size": 1536,
      "seed": 79778705783779,
      "steps": 8,
      "cfg": 1.2000000000000002,
      "sampler_name": "lcm",
      "scheduler": "normal",
      "denoise": 0.25000000000000006,
      "feather": 100,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.5,
      "bbox_dilation": 10,
      "bbox_crop_factor": 3,
      "sam_detection_hint": "center-1",
      "sam_dilation": 0,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": "",
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "tiled_encode": false,
      "tiled_decode": false,
      "image": [
        "496",
        0
      ],
      "model": [
        "423",
        0
      ],
      "clip": [
        "423",
        1
      ],
      "vae": [
        "503",
        2
      ],
      "positive": [
        "490",
        0
      ],
      "negative": [
        "487",
        4
      ],
      "bbox_detector": [
        "486",
        0
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "2 - Hand Detailer"
    }
  },
  "496": {
    "inputs": {
      "guide_size": 1536,
      "guide_size_for": true,
      "max_size": 1536,
      "seed": 1036520970017657,
      "steps": 8,
      "cfg": 1.2000000000000002,
      "sampler_name": "lcm",
      "scheduler": "normal",
      "denoise": 0.15000000000000002,
      "feather": 80,
      "noise_mask": true,
      "force_inpaint": true,
      "bbox_threshold": 0.5,
      "bbox_dilation": 150,
      "bbox_crop_factor": 3,
      "sam_detection_hint": "center-1",
      "sam_dilation": 0,
      "sam_threshold": 0.93,
      "sam_bbox_expansion": 0,
      "sam_mask_hint_threshold": 0.7,
      "sam_mask_hint_use_negative": "False",
      "drop_size": 10,
      "wildcard": "",
      "cycle": 1,
      "inpaint_model": false,
      "noise_mask_feather": 20,
      "tiled_encode": false,
      "tiled_decode": false,
      "image": [
        "292",
        0
      ],
      "model": [
        "423",
        0
      ],
      "clip": [
        "423",
        1
      ],
      "vae": [
        "503",
        2
      ],
      "positive": [
        "493",
        0
      ],
      "negative": [
        "489",
        0
      ],
      "bbox_detector": [
        "488",
        0
      ]
    },
    "class_type": "FaceDetailer",
    "_meta": {
      "title": "FaceDetailer"
    }
  },
  "503": {
    "inputs": {
      "ckpt_name": "Perfection_ILXL_Realistic_3.3.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "509": {
    "inputs": {
      "model_name": "4x-UltraSharp.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "510": {
    "inputs": {
      "upscale_model": [
        "509",
        0
      ],
      "image": [
        "55",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "511": {
    "inputs": {
      "factor": 0.5000000000000001,
      "resampler": "nearest",
      "IMAGE": [
        "510",
        0
      ]
    },
    "class_type": "JDC_ResizeFactor",
    "_meta": {
      "title": "Resize Image by Factor"
    }
  },
  "512": {
    "inputs": {
      "size": 1920,
      "interpolation_mode": "bicubic",
      "image": [
        "510",
        0
      ]
    },
    "class_type": "JWImageResizeByLongerSide",
    "_meta": {
      "title": "Image Resize by Longer Side"
    }
  },
  "513": {
    "inputs": {
      "pixels": [
        "512",
        0
      ],
      "vae": [
        "503",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  }
}
